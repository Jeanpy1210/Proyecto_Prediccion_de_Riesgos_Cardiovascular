{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas numpy matplotlib seaborn scikit-learn tensorflow keras gradio google-generativeai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcezFdUiaN1Q",
        "outputId": "44300e8f-1814-4a1d-f0b7-05edad3f41eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.29.0)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.15.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.10.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.31.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.9)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.3)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.24.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.169.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.19.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LRDVsNDzXycr",
        "outputId": "d5f7c4d6-7500-409f-df03-03f06910b030"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¡Bienvenido al Sistema de Predicción del Riesgo Cardiovascular!\n",
            "Este notebook te permite:\n",
            "1. Cargar un archivo CSV o XLSX con datos de conductores (puede tener múltiples filas, ej. 1000)\n",
            "2. Configurar el análisis seleccionando variables objetivo, categóricas y numéricas\n",
            "3. Analizar datos (estadísticas y visualizaciones basadas en todas las filas)\n",
            "4. Predecir el riesgo cardiovascular usando un modelo de red neuronal\n",
            "5. Consultar patrones y recomendaciones con Gemini AI\n",
            "\n",
            "Ejecuta la siguiente celda para iniciar la interfaz.\n",
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://b550d23a7ab8f3d723.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://b550d23a7ab8f3d723.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ API de Gemini configurada correctamente\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gradio/components/dropdown.py:227: UserWarning: The value passed into gr.Dropdown() is not in the list of choices. Please update the list of choices to include: ['Riesgo_Cardiovascular'] or set allow_custom_value=True.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/gradio/components/dropdown.py:227: UserWarning: The value passed into gr.Dropdown() is not in the list of choices. Please update the list of choices to include: ['Riesgo_Cardiovascular'] or set allow_custom_value=True.\n",
            "  warnings.warn(\n",
            "<ipython-input-6-694e16ca2a38>:95: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.countplot(x=target_col, data=df, palette='Blues')\n",
            "<ipython-input-6-694e16ca2a38>:115: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(x=value_counts.index, y=value_counts.values, palette='Blues')\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "<ipython-input-6-694e16ca2a38>:95: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.countplot(x=target_col, data=df, palette='Blues')\n",
            "<ipython-input-6-694e16ca2a38>:115: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(x=value_counts.index, y=value_counts.values, palette='Blues')\n",
            "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7e92ec9beb60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-694e16ca2a38>:243: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(x=top_features.values, y=top_features.index, palette='Blues')\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import google.generativeai as genai\n",
        "import gradio as gr\n",
        "import io\n",
        "import os\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from IPython.display import display, HTML\n",
        "from pathlib import Path\n",
        "\n",
        "# Create visualizations directory\n",
        "if not os.path.exists('visualizations'):\n",
        "    os.makedirs('visualizations')\n",
        "\n",
        "\"\"\"## Configuración de la API de Gemini AI\"\"\"\n",
        "def setup_gemini_api(api_key):\n",
        "    try:\n",
        "        genai.configure(api_key=api_key)\n",
        "        model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "        print(\"✅ API de Gemini configurada correctamente\")\n",
        "        return True, model\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error al configurar la API de Gemini: {e}\")\n",
        "        print(\"Intenta listar los modelos disponibles con el siguiente código:\")\n",
        "        print(\"\"\"\n",
        "        import google.generativeai as genai\n",
        "        genai.configure(api_key='YOUR_API_KEY')\n",
        "        for model in genai.list_models():\n",
        "            print(f\"Model: {model.name}, Supported Methods: {model.supported_generation_methods}\")\n",
        "        \"\"\")\n",
        "        return False, None\n",
        "\n",
        "\"\"\"## Funciones para el análisis de datos\"\"\"\n",
        "def generate_csv_stats(df, max_preview_rows=100):\n",
        "    buffer = io.StringIO()\n",
        "    buffer.write(f\"### Información general del archivo\\n\")\n",
        "    buffer.write(f\"- Número de filas: {df.shape[0]}\\n\")\n",
        "    buffer.write(f\"- Número de columnas: {df.shape[1]}\\n\")\n",
        "    buffer.write(f\"- Columnas: {', '.join(df.columns.tolist())}\\n\\n\")\n",
        "\n",
        "    # Vista previa personalizable\n",
        "    buffer.write(\"### Vista previa de los datos\\n\")\n",
        "    if df.shape[0] > max_preview_rows:\n",
        "        buffer.write(f\"Mostrando las primeras {max_preview_rows} filas de {df.shape[0]} totales:\\n\")\n",
        "        buffer.write(df.head(max_preview_rows).to_string())\n",
        "    else:\n",
        "        buffer.write(\"Dataset completo:\\n\")\n",
        "        buffer.write(df.to_string())\n",
        "    buffer.write(\"\\n\\n\")\n",
        "\n",
        "    numeric_df = df.select_dtypes(include=[np.number])\n",
        "    if not numeric_df.empty:\n",
        "        buffer.write(\"### Estadísticas descriptivas (basadas en todas las filas)\\n\")\n",
        "        buffer.write(numeric_df.describe().to_string())\n",
        "    else:\n",
        "        buffer.write(\"No hay columnas numéricas para mostrar estadísticas.\\n\")\n",
        "    buffer.write(\"\\n\\n### Valores faltantes\\n\")\n",
        "    missing_values = df.isnull().sum()\n",
        "    missing_df = pd.DataFrame({\n",
        "        'Columna': missing_values.index,\n",
        "        'Valores faltantes': missing_values.values,\n",
        "        'Porcentaje': (missing_values.values / len(df)) * 100\n",
        "    })\n",
        "    buffer.write(missing_df.to_string(index=False))\n",
        "    buffer.write(\"\\n\\n### Tipos de datos\\n\")\n",
        "    dtypes_df = pd.DataFrame({\n",
        "        'Columna': df.dtypes.index,\n",
        "        'Tipo': df.dtypes.values\n",
        "    })\n",
        "    buffer.write(dtypes_df.to_string(index=False))\n",
        "    return buffer.getvalue()\n",
        "\n",
        "def generate_visualizations(df, target_col=None, cat_col=None):\n",
        "    plots_info = []\n",
        "\n",
        "    # Automatically select target and categorical columns if not provided\n",
        "    if target_col is None:\n",
        "        target_col = 'Riesgo_Cardiovascular'\n",
        "    if cat_col is None:\n",
        "        cat_cols = df.select_dtypes(include=['object', 'category']).columns\n",
        "        cat_col = cat_cols[0] if len(cat_cols) > 0 else None\n",
        "\n",
        "    if df.shape[0] < 10:\n",
        "        print(\"⚠️ Advertencia: El dataset tiene menos de 10 filas, lo que puede limitar la calidad de las visualizaciones.\")\n",
        "\n",
        "    # 1. Bar plot of target column distribution\n",
        "    if target_col and target_col in df.columns:\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.countplot(x=target_col, data=df, palette='Blues')\n",
        "        plt.title('Distribución del Riesgo Cardiovascular', fontsize=14)\n",
        "        plt.xlabel('Riesgo Cardiovascular (0: Bajo, 1: Alto)', fontsize=12)\n",
        "        plt.ylabel('Frecuencia', fontsize=12)\n",
        "        plt.tight_layout()\n",
        "        filename = 'visualizations/dist_target.png'\n",
        "        plt.savefig(filename)\n",
        "        plt.close()\n",
        "        plots_info.append({\n",
        "            'title': 'Distribución del Riesgo Cardiovascular',\n",
        "            'filename': filename,\n",
        "            'type': 'barplot'\n",
        "        })\n",
        "\n",
        "    # 2. Bar plot of top categories\n",
        "    if cat_col and cat_col in df.columns:\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        value_counts = df[cat_col].value_counts().head(10)\n",
        "        if len(value_counts) < 2:\n",
        "            print(f\"⚠️ Advertencia: La categoría seleccionada tiene menos de 2 valores únicos, lo que limita el análisis.\")\n",
        "        sns.barplot(x=value_counts.index, y=value_counts.values, palette='Blues')\n",
        "        plt.title(f'Conteo de categorías en {cat_col} (Top 10)', fontsize=14)\n",
        "        plt.xticks(rotation=45, ha='right', fontsize=10)\n",
        "        plt.ylabel('Cantidad', fontsize=12)\n",
        "        plt.tight_layout()\n",
        "        filename = 'visualizations/count_category.png'\n",
        "        plt.savefig(filename)\n",
        "        plt.close()\n",
        "        plots_info.append({\n",
        "            'title': f'Conteo de categorías en {cat_col} (Top 10)',\n",
        "            'filename': filename,\n",
        "            'type': 'barplot'\n",
        "        })\n",
        "\n",
        "    # 3. Correlation heatmap\n",
        "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "    if len(numeric_cols) > 1:\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        corr_matrix = df[numeric_cols].corr()\n",
        "        mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
        "        sns.heatmap(corr_matrix, mask=mask, annot=True, cmap='Blues', fmt='.2f')\n",
        "        plt.title('Matriz de Correlación', fontsize=14)\n",
        "        plt.tight_layout()\n",
        "        filename = 'visualizations/correlation_matrix.png'\n",
        "        plt.savefig(filename)\n",
        "        plt.close()\n",
        "        plots_info.append({\n",
        "            'title': 'Matriz de Correlación',\n",
        "            'filename': filename,\n",
        "            'type': 'heatmap'\n",
        "        })\n",
        "\n",
        "    return plots_info\n",
        "\n",
        "\"\"\"## Predicción de Riesgo Cardiovascular\"\"\"\n",
        "def preprocess_data(df, target_col=None, categorical_cols=None, numerical_cols=None):\n",
        "    if df.shape[0] < 10:\n",
        "        raise ValueError(\"El dataset tiene menos de 10 filas, lo que es insuficiente para entrenar un modelo.\")\n",
        "\n",
        "    # Específico para el dataset conductores_salud\n",
        "    target_col = 'Riesgo_Cardiovascular'\n",
        "    categorical_cols = ['Genero', 'Fuma']\n",
        "    numerical_cols = ['Edad', 'IMC', 'Colesterol', 'Trigliceridos', 'Frecuencia_Cardiaca',\n",
        "                      'Presion_Sistolica', 'Presion_Diastolica', 'Nivel_Estres', 'Actividad_Fisica']\n",
        "\n",
        "    # Verificar que las columnas requeridas estén presentes\n",
        "    required_cols = [target_col] + categorical_cols + numerical_cols\n",
        "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
        "    if missing_cols:\n",
        "        raise ValueError(f\"Faltan las siguientes columnas en el archivo: {', '.join(missing_cols)}\")\n",
        "\n",
        "    # Handle missing values\n",
        "    df = df.dropna(subset=[target_col])\n",
        "    for col in numerical_cols:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "        df[col] = df[col].fillna(df[col].median())\n",
        "    for col in categorical_cols:\n",
        "        df[col] = df[col].fillna(df[col].mode()[0])\n",
        "\n",
        "    # Encode categorical variables\n",
        "    le = LabelEncoder()\n",
        "    for col in categorical_cols:\n",
        "        df[col] = le.fit_transform(df[col])\n",
        "\n",
        "    # Normalize numerical features\n",
        "    scaler = StandardScaler()\n",
        "    df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
        "\n",
        "    return df, scaler, target_col\n",
        "\n",
        "def train_model(df_encoded, target_col):\n",
        "    X = df_encoded.drop(columns=[target_col], axis=1)\n",
        "    y = df_encoded[target_col]\n",
        "\n",
        "    # Verify numeric data\n",
        "    non_numeric_cols = X.select_dtypes(exclude=[np.number]).columns\n",
        "    if len(non_numeric_cols) > 0:\n",
        "        raise ValueError(f\"El conjunto de características contiene columnas no numéricas: {non_numeric_cols.tolist()}\")\n",
        "\n",
        "    # Split the data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Build the Keras model for binary classification\n",
        "    model = Sequential([\n",
        "        Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(16, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    # Compile and train\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=0)\n",
        "\n",
        "    # Evaluate\n",
        "    y_pred_prob = model.predict(X_test)\n",
        "    y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
        "\n",
        "    # Metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    # Generate visualizations\n",
        "    plots_info = []\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "    plt.title('Matriz de Confusión')\n",
        "    plt.xlabel('Predicho')\n",
        "    plt.ylabel('Real')\n",
        "    plt.tight_layout()\n",
        "    filename = 'visualizations/confusion_matrix.png'\n",
        "    plt.savefig(filename)\n",
        "    plt.close()\n",
        "    plots_info.append({\n",
        "        'title': 'Matriz de Confusión',\n",
        "        'filename': filename,\n",
        "        'type': 'heatmap'\n",
        "    })\n",
        "\n",
        "    # Feature Importance (Correlation-based)\n",
        "    correlations = df_encoded.corr()[target_col].abs().sort_values(ascending=False)\n",
        "    top_features = correlations[1:6]\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.barplot(x=top_features.values, y=top_features.index, palette='Blues')\n",
        "    plt.title('Importancia de Características (Correlación)', fontsize=14)\n",
        "    plt.xlabel('Correlación Absoluta', fontsize=12)\n",
        "    plt.tight_layout()\n",
        "    filename = 'visualizations/feature_importance.png'\n",
        "    plt.savefig(filename)\n",
        "    plt.close()\n",
        "    plots_info.append({\n",
        "        'title': 'Importancia de Características',\n",
        "        'filename': filename,\n",
        "        'type': 'barplot'\n",
        "    })\n",
        "\n",
        "    return accuracy, precision, recall, f1, plots_info, model, X_test, y_test, y_pred, correlations\n",
        "\n",
        "\"\"\"## Integración con Gemini API\"\"\"\n",
        "def query_gemini_analysis(df, query, model, target_col='Riesgo_Cardiovascular', cat_col=None, year_col=None, region_cols=None):\n",
        "    try:\n",
        "        if df.shape[0] < 10:\n",
        "            return \"⚠️ Los datos son insuficientes (menos de 10 filas). Por favor, proporciona un dataset más grande para un análisis confiable.\"\n",
        "\n",
        "        # Automatically select columns\n",
        "        if cat_col is None:\n",
        "            cat_col = 'Genero'\n",
        "        if year_col is None:\n",
        "            year_col = None\n",
        "        if region_cols is None:\n",
        "            region_cols = []\n",
        "\n",
        "        # Prepare data summary for Gemini\n",
        "        df_info = df.head(100).to_string()  # Mostrar las primeras 100 filas como muestra\n",
        "        columns_info = \"\\n\".join([f\"- {col}: {df[col].dtype}\" for col in df.columns])\n",
        "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "        stats = \"\\n\".join([f\"- {col}: min={df[col].min()}, max={df[col].max()}, mean={df[col].mean()}\" for col in numeric_cols])\n",
        "\n",
        "        # Common instructions for all prompts\n",
        "        base_instructions = \"\"\"\n",
        "        Instrucciones:\n",
        "        - Responde SOLO a la consulta proporcionada, utilizando únicamente los datos y el análisis proporcionados.\n",
        "        - NO hagas suposiciones ni generes datos hipotéticos.\n",
        "        - Proporciona una respuesta concisa, clara y accionable.\n",
        "        - Si los datos son insuficientes, indica claramente que los datos son limitados y sugiere cómo obtener un análisis más robusto.\n",
        "        - Evita añadir información o recomendaciones no solicitadas.\n",
        "        \"\"\"\n",
        "\n",
        "        # Specific analysis for predefined questions\n",
        "        if \"highest\" in query.lower() and \"potential\" in query.lower() and cat_col:\n",
        "            df_encoded, _, _ = preprocess_data(df, target_col, ['Genero', 'Fuma'])\n",
        "            accuracy, precision, recall, f1, _, model, X_test, y_test, y_pred, _ = train_model(df_encoded, target_col)\n",
        "            category_risk = df.groupby(cat_col)[target_col].mean().sort_values(ascending=False)\n",
        "            top_category = category_risk.index[0]\n",
        "            prompt = f\"\"\"\n",
        "            {base_instructions}\n",
        "\n",
        "            Datos:\n",
        "            COLUMNAS:\n",
        "            {columns_info}\n",
        "\n",
        "            ESTADÍSTICAS:\n",
        "            {stats}\n",
        "\n",
        "            MUESTRA:\n",
        "            {df_info}\n",
        "\n",
        "            Análisis: La categoría con mayor riesgo promedio es '{top_category}' con {category_risk.iloc[0]:.2f} (Accuracy del modelo: {accuracy:.2f}). Nota: Los datos tienen {df.shape[0]} filas.\n",
        "            Confirma este resultado y explica brevemente, en no más de 100 palabras, por qué esta categoría tiene alto riesgo cardiovascular, basándote en el modelo y los datos. Sugiere cómo mejorar el análisis con más datos.\n",
        "            \"\"\"\n",
        "        elif \"combination\" in query.lower() and \"potential\" in query.lower():\n",
        "            cat_cols = ['Genero', 'Fuma']\n",
        "            df_encoded, _, _ = preprocess_data(df, target_col, cat_cols)\n",
        "            accuracy, precision, recall, f1, _, model, X_test, y_test, y_pred, _ = train_model(df_encoded, target_col)\n",
        "            combo_risk = df.groupby(cat_cols)[target_col].mean().sort_values(ascending=False)\n",
        "            if not combo_risk.empty:\n",
        "                top_combo = combo_risk.index[0]\n",
        "                top_risk = combo_risk.iloc[0]\n",
        "                prompt = f\"\"\"\n",
        "                {base_instructions}\n",
        "\n",
        "                Datos:\n",
        "                COLUMNAS:\n",
        "                {columns_info}\n",
        "\n",
        "                ESTADÍSTICAS:\n",
        "                {stats}\n",
        "\n",
        "                MUESTRA:\n",
        "                {df_info}\n",
        "\n",
        "                Análisis: La combinación con mayor riesgo es '{top_combo[0]}'/'{top_combo[1]}' con {top_risk:.2f} (Accuracy del modelo: {accuracy:.2f}). Nota: Los datos tienen {df.shape[0]} filas.\n",
        "                Confirma este resultado y explica brevemente, en no más de 100 palabras, por qué esta combinación tiene alto riesgo, basándote en el modelo. Sugiere cómo mejorar el análisis con más datos.\n",
        "                \"\"\"\n",
        "            else:\n",
        "                return \"⚠️ Los datos no contienen información suficiente para determinar combinaciones de categorías.\"\n",
        "        elif \"marketing strategies\" in query.lower() and cat_col:\n",
        "            df_encoded, _, _ = preprocess_data(df, target_col, ['Genero', 'Fuma'])\n",
        "            accuracy, precision, recall, f1, _, model, X_test, y_test, y_pred, _ = train_model(df_encoded, target_col)\n",
        "            top_cats = df.groupby(cat_col)[target_col].mean().sort_values(ascending=False).head(2).index.tolist()\n",
        "            prompt = f\"\"\"\n",
        "            {base_instructions}\n",
        "\n",
        "            Datos:\n",
        "            COLUMNAS:\n",
        "            {columns_info}\n",
        "\n",
        "            ESTADÍSTICAS:\n",
        "            {stats}\n",
        "\n",
        "            MUESTRA:\n",
        "            {df_info}\n",
        "\n",
        "            Análisis: Las categorías con mayor riesgo son {', '.join(top_cats)}. Modelo Accuracy: {accuracy:.2f}. Nota: Los datos tienen {df.shape[0]} filas.\n",
        "            Genera 3 estrategias de prevención específicas y breves (máximo 50 palabras cada una) para reducir el riesgo cardiovascular en estas categorías, basándote en el modelo y los datos. Sugiere cómo mejorar las estrategias con más datos.\n",
        "            \"\"\"\n",
        "        else:\n",
        "            prompt = f\"\"\"\n",
        "            {base_instructions}\n",
        "\n",
        "            Datos:\n",
        "            COLUMNAS:\n",
        "            {columns_info}\n",
        "\n",
        "            ESTADÍSTICAS:\n",
        "            {stats}\n",
        "\n",
        "            MUESTRA:\n",
        "            {df_info}\n",
        "\n",
        "            Consulta: {query}\n",
        "            Responde únicamente a la consulta, utilizando los datos proporcionados. Proporciona un análisis claro, conciso y accionable en no más de 150 palabras. Si los datos son insuficientes, indícalos claramente y sugiere cómo obtener un análisis más robusto.\n",
        "            \"\"\"\n",
        "\n",
        "        # Query Gemini API\n",
        "        response = model.generate_content(prompt)\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        return f\"Error al consultar a Gemini: {str(e)}\"\n",
        "\n",
        "\"\"\"## Interfaz de usuario con Gradio\"\"\"\n",
        "def create_gradio_interface():\n",
        "    df = None\n",
        "    model = None\n",
        "    gemini_model = None\n",
        "    X_test = None\n",
        "    y_test = None\n",
        "    y_pred = None\n",
        "    target_col = 'Riesgo_Cardiovascular'\n",
        "    categorical_cols = ['Genero', 'Fuma']\n",
        "    numerical_cols = ['Edad', 'IMC', 'Colesterol', 'Trigliceridos', 'Frecuencia_Cardiaca',\n",
        "                      'Presion_Sistolica', 'Presion_Diastolica', 'Nivel_Estres', 'Actividad_Fisica']\n",
        "\n",
        "    def upload_file(file):\n",
        "        try:\n",
        "            nonlocal df, target_col, categorical_cols, numerical_cols\n",
        "            file_extension = os.path.splitext(file.name)[1].lower()\n",
        "            if file_extension == '.csv':\n",
        "                df = pd.read_csv(file.name)\n",
        "            elif file_extension == '.xlsx':\n",
        "                df = pd.read_excel(file.name, engine='openpyxl')\n",
        "            else:\n",
        "                return None, \"Formato no soportado. Usa .csv o .xlsx.\", \"Error\", [], [], []\n",
        "\n",
        "            # Corregir codificación de 'SÃ­' a 'Sí'\n",
        "            if 'Fuma' in df.columns:\n",
        "                df['Fuma'] = df['Fuma'].replace('SÃ­', 'Sí')\n",
        "\n",
        "            stats = generate_csv_stats(df, max_preview_rows=100)\n",
        "            return (df.head(100).to_html(), stats, f\"Archivo {file_extension} cargado correctamente. Total de filas: {df.shape[0]}\",\n",
        "                    [target_col], categorical_cols, numerical_cols)\n",
        "        except Exception as e:\n",
        "            return None, f\"Error al cargar el archivo: {str(e)}\", \"Error\", [], [], []\n",
        "\n",
        "    def update_columns(selected_target, selected_categorical, selected_numerical):\n",
        "        nonlocal target_col, categorical_cols, numerical_cols\n",
        "        target_col = selected_target\n",
        "        categorical_cols = selected_categorical\n",
        "        numerical_cols = selected_numerical\n",
        "        return f\"Configuración actualizada: Objetivo seleccionado, {len(categorical_cols)} categorías, {len(numerical_cols)} variables numéricas\"\n",
        "\n",
        "    def set_api_key(api_key):\n",
        "        nonlocal gemini_model\n",
        "        success, model_instance = setup_gemini_api(api_key)\n",
        "        if success:\n",
        "            gemini_model = model_instance\n",
        "            return \"API de Gemini configurada correctamente\", api_key\n",
        "        else:\n",
        "            return \"Error al configurar la API de Gemini\", \"\"\n",
        "\n",
        "    def ask_gemini(query, api_key):\n",
        "        nonlocal df, gemini_model, target_col, categorical_cols\n",
        "        if df is None:\n",
        "            return \"Primero debes cargar un archivo CSV o XLSX\"\n",
        "        if not api_key or gemini_model is None:\n",
        "            return \"Primero debes configurar la API de Gemini\"\n",
        "        try:\n",
        "            cat_col = categorical_cols[0] if categorical_cols else None\n",
        "            return query_gemini_analysis(df, query, gemini_model, target_col, cat_col)\n",
        "        except Exception as e:\n",
        "            return f\"Error al consultar a Gemini: {str(e)}\"\n",
        "\n",
        "    def generate_plots():\n",
        "        nonlocal df, target_col, categorical_cols\n",
        "        if df is None:\n",
        "            return \"Primero debes cargar un archivo CSV o XLSX\", []\n",
        "        try:\n",
        "            cat_col = categorical_cols[0] if categorical_cols else None\n",
        "            plots_info = generate_visualizations(df, target_col, cat_col)\n",
        "            return \"Visualizaciones generadas correctamente\", [plot['filename'] for plot in plots_info]\n",
        "        except Exception as e:\n",
        "            return f\"Error al generar visualizaciones: {str(e)}\", []\n",
        "\n",
        "    def train_and_evaluate():\n",
        "        nonlocal df, model, X_test, y_test, y_pred, target_col, categorical_cols, numerical_cols\n",
        "        if df is None:\n",
        "            return \"Primero debes cargar un archivo CSV o XLSX\", [], \"\"\n",
        "        try:\n",
        "            df_encoded, _, target_col = preprocess_data(df, target_col, categorical_cols, numerical_cols)\n",
        "            accuracy, precision, recall, f1, plots_info, model, X_test, y_test, y_pred, _ = train_model(df_encoded, target_col)\n",
        "            metrics = f\"Accuracy: {accuracy:.4f}\\nPrecision: {precision:.4f}\\nRecall: {recall:.4f}\\nF1-Score: {f1:.4f}\"\n",
        "            return metrics, [plot['filename'] for plot in plots_info], \"Modelo entrenado correctamente\"\n",
        "        except Exception as e:\n",
        "            return f\"Error al entrenar el modelo: {str(e)}\", [], \"Error\"\n",
        "\n",
        "    with gr.Blocks(title=\"Predicción del Riesgo Cardiovascular\") as app:\n",
        "        gr.Markdown(\"# 📊 Predicción del Riesgo Cardiovascular\")\n",
        "        gr.Markdown(\"Carga un archivo CSV o XLSX con datos de salud (puede tener múltiples filas, ej. 1000), analiza los datos, predice el riesgo cardiovascular y consulta patrones con Gemini AI.\")\n",
        "        saved_api_key = gr.State(\"\")\n",
        "        with gr.Tab(\"Cargar Datos\"):\n",
        "            with gr.Row():\n",
        "                with gr.Column(scale=1):\n",
        "                    file_input = gr.File(label=\"Selecciona un archivo CSV o XLSX\", file_types=[\".csv\", \".xlsx\"])\n",
        "                    upload_button = gr.Button(\"Cargar Archivo\")\n",
        "                    upload_status = gr.Textbox(label=\"Estado\", interactive=False)\n",
        "                with gr.Column(scale=2):\n",
        "                    data_preview = gr.HTML(label=\"Vista previa (Primeras 100 filas)\")\n",
        "                    data_stats = gr.Textbox(label=\"Estadísticas (Basadas en todas las filas)\", interactive=False, max_lines=30)\n",
        "        with gr.Tab(\"Configurar Análisis\"):\n",
        "            target_dropdown = gr.Dropdown(label=\"Variable Objetivo\", choices=['Riesgo_Cardiovascular'], value='Riesgo_Cardiovascular', interactive=True)\n",
        "            categorical_checklist = gr.CheckboxGroup(label=\"Variables Categóricas\", choices=['Genero', 'Fuma'], value=['Genero', 'Fuma'], interactive=True)\n",
        "            numerical_checklist = gr.CheckboxGroup(label=\"Variables Numéricas\", choices=['Edad', 'IMC', 'Colesterol', 'Trigliceridos', 'Frecuencia_Cardiaca',\n",
        "                                                                                       'Presion_Sistolica', 'Presion_Diastolica', 'Nivel_Estres', 'Actividad_Fisica'],\n",
        "                                                  value=['Edad', 'IMC', 'Colesterol', 'Trigliceridos', 'Frecuencia_Cardiaca',\n",
        "                                                         'Presion_Sistolica', 'Presion_Diastolica', 'Nivel_Estres', 'Actividad_Fisica'], interactive=True)\n",
        "            update_button = gr.Button(\"Actualizar Configuración\")\n",
        "            column_status = gr.Textbox(label=\"Estado de Configuración\", interactive=False)\n",
        "        with gr.Tab(\"Configurar API\"):\n",
        "            gemini_api_key = gr.Textbox(label=\"API Key de Gemini AI\", type=\"password\")\n",
        "            api_button = gr.Button(\"Configurar API\")\n",
        "            api_status = gr.Textbox(label=\"Estado\", interactive=False)\n",
        "        with gr.Tab(\"Consultar Datos\"):\n",
        "            query_input = gr.Textbox(label=\"Consulta sobre los datos\", placeholder=\"Ej: ¿Qué categoría tiene mayor riesgo cardiovascular?\")\n",
        "            query_button = gr.Button(\"Consultar a Gemini AI\")\n",
        "            query_result = gr.Markdown(label=\"Respuesta\")\n",
        "        with gr.Tab(\"Visualizaciones\"):\n",
        "            viz_button = gr.Button(\"Generar Visualizaciones\")\n",
        "            viz_status = gr.Textbox(label=\"Estado\", interactive=False)\n",
        "            viz_gallery = gr.Gallery(label=\"Gráficos\", show_label=True, columns=2, rows=3, height=600)\n",
        "        with gr.Tab(\"Predicción\"):\n",
        "            pred_button = gr.Button(\"Entrenar y Evaluar Modelo\")\n",
        "            pred_metrics = gr.Textbox(label=\"Métricas del Modelo\", interactive=False)\n",
        "            pred_gallery = gr.Gallery(label=\"Gráficos de Predicción\", show_label=True, columns=2, rows=2, height=600)\n",
        "            pred_status = gr.Textbox(label=\"Estado\", interactive=False)\n",
        "\n",
        "        upload_button.click(\n",
        "            upload_file,\n",
        "            inputs=[file_input],\n",
        "            outputs=[data_preview, data_stats, upload_status, target_dropdown, categorical_checklist, numerical_checklist]\n",
        "        )\n",
        "        update_button.click(\n",
        "            update_columns,\n",
        "            inputs=[target_dropdown, categorical_checklist, numerical_checklist],\n",
        "            outputs=[column_status]\n",
        "        )\n",
        "        api_button.click(set_api_key, inputs=[gemini_api_key], outputs=[api_status, saved_api_key])\n",
        "        query_button.click(ask_gemini, inputs=[query_input, saved_api_key], outputs=[query_result])\n",
        "        viz_button.click(generate_plots, inputs=[], outputs=[viz_status, viz_gallery])\n",
        "        pred_button.click(train_and_evaluate, inputs=[], outputs=[pred_metrics, pred_gallery, pred_status])\n",
        "\n",
        "    return app\n",
        "\n",
        "\"\"\"## Iniciar la aplicación\"\"\"\n",
        "print(\"¡Bienvenido al Sistema de Predicción del Riesgo Cardiovascular!\")\n",
        "print(\"Este notebook te permite:\")\n",
        "print(\"1. Cargar un archivo CSV o XLSX con datos de conductores (puede tener múltiples filas, ej. 1000)\")\n",
        "print(\"2. Configurar el análisis seleccionando variables objetivo, categóricas y numéricas\")\n",
        "print(\"3. Analizar datos (estadísticas y visualizaciones basadas en todas las filas)\")\n",
        "print(\"4. Predecir el riesgo cardiovascular usando un modelo de red neuronal\")\n",
        "print(\"5. Consultar patrones y recomendaciones con Gemini AI\")\n",
        "print(\"\\nEjecuta la siguiente celda para iniciar la interfaz.\")\n",
        "app = create_gradio_interface()\n",
        "app.launch(debug=True)\n",
        "\n",
        "\"\"\"\n",
        "## Instrucciones de uso\n",
        "\n",
        "1. **Instalar dependencias**:\n",
        "   - Ejecuta en Colab:\n",
        "     ```bash\n",
        "     !pip install numpy pandas matplotlib seaborn tensorflow google-generativeai gradio scikit-learn openpyxl\"\"\""
      ]
    }
  ]
}