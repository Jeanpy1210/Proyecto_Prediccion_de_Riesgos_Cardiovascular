{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas numpy matplotlib seaborn scikit-learn tensorflow keras gradio google-generativeai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcezFdUiaN1Q",
        "outputId": "44300e8f-1814-4a1d-f0b7-05edad3f41eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (3.8.0)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.29.0)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras) (0.0.9)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras) (0.15.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.10.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.31.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.9)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.3)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.24.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.169.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras) (2.19.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LRDVsNDzXycr",
        "outputId": "d5f7c4d6-7500-409f-df03-03f06910b030"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "¬°Bienvenido al Sistema de Predicci√≥n del Riesgo Cardiovascular!\n",
            "Este notebook te permite:\n",
            "1. Cargar un archivo CSV o XLSX con datos de conductores (puede tener m√∫ltiples filas, ej. 1000)\n",
            "2. Configurar el an√°lisis seleccionando variables objetivo, categ√≥ricas y num√©ricas\n",
            "3. Analizar datos (estad√≠sticas y visualizaciones basadas en todas las filas)\n",
            "4. Predecir el riesgo cardiovascular usando un modelo de red neuronal\n",
            "5. Consultar patrones y recomendaciones con Gemini AI\n",
            "\n",
            "Ejecuta la siguiente celda para iniciar la interfaz.\n",
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://b550d23a7ab8f3d723.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://b550d23a7ab8f3d723.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ API de Gemini configurada correctamente\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gradio/components/dropdown.py:227: UserWarning: The value passed into gr.Dropdown() is not in the list of choices. Please update the list of choices to include: ['Riesgo_Cardiovascular'] or set allow_custom_value=True.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/gradio/components/dropdown.py:227: UserWarning: The value passed into gr.Dropdown() is not in the list of choices. Please update the list of choices to include: ['Riesgo_Cardiovascular'] or set allow_custom_value=True.\n",
            "  warnings.warn(\n",
            "<ipython-input-6-694e16ca2a38>:95: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.countplot(x=target_col, data=df, palette='Blues')\n",
            "<ipython-input-6-694e16ca2a38>:115: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(x=value_counts.index, y=value_counts.values, palette='Blues')\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "<ipython-input-6-694e16ca2a38>:95: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.countplot(x=target_col, data=df, palette='Blues')\n",
            "<ipython-input-6-694e16ca2a38>:115: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(x=value_counts.index, y=value_counts.values, palette='Blues')\n",
            "WARNING:tensorflow:5 out of the last 15 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7e92ec9beb60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-694e16ca2a38>:243: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `y` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.barplot(x=top_features.values, y=top_features.index, palette='Blues')\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import google.generativeai as genai\n",
        "import gradio as gr\n",
        "import io\n",
        "import os\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from IPython.display import display, HTML\n",
        "from pathlib import Path\n",
        "\n",
        "# Create visualizations directory\n",
        "if not os.path.exists('visualizations'):\n",
        "    os.makedirs('visualizations')\n",
        "\n",
        "\"\"\"## Configuraci√≥n de la API de Gemini AI\"\"\"\n",
        "def setup_gemini_api(api_key):\n",
        "    try:\n",
        "        genai.configure(api_key=api_key)\n",
        "        model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "        print(\"‚úÖ API de Gemini configurada correctamente\")\n",
        "        return True, model\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error al configurar la API de Gemini: {e}\")\n",
        "        print(\"Intenta listar los modelos disponibles con el siguiente c√≥digo:\")\n",
        "        print(\"\"\"\n",
        "        import google.generativeai as genai\n",
        "        genai.configure(api_key='YOUR_API_KEY')\n",
        "        for model in genai.list_models():\n",
        "            print(f\"Model: {model.name}, Supported Methods: {model.supported_generation_methods}\")\n",
        "        \"\"\")\n",
        "        return False, None\n",
        "\n",
        "\"\"\"## Funciones para el an√°lisis de datos\"\"\"\n",
        "def generate_csv_stats(df, max_preview_rows=100):\n",
        "    buffer = io.StringIO()\n",
        "    buffer.write(f\"### Informaci√≥n general del archivo\\n\")\n",
        "    buffer.write(f\"- N√∫mero de filas: {df.shape[0]}\\n\")\n",
        "    buffer.write(f\"- N√∫mero de columnas: {df.shape[1]}\\n\")\n",
        "    buffer.write(f\"- Columnas: {', '.join(df.columns.tolist())}\\n\\n\")\n",
        "\n",
        "    # Vista previa personalizable\n",
        "    buffer.write(\"### Vista previa de los datos\\n\")\n",
        "    if df.shape[0] > max_preview_rows:\n",
        "        buffer.write(f\"Mostrando las primeras {max_preview_rows} filas de {df.shape[0]} totales:\\n\")\n",
        "        buffer.write(df.head(max_preview_rows).to_string())\n",
        "    else:\n",
        "        buffer.write(\"Dataset completo:\\n\")\n",
        "        buffer.write(df.to_string())\n",
        "    buffer.write(\"\\n\\n\")\n",
        "\n",
        "    numeric_df = df.select_dtypes(include=[np.number])\n",
        "    if not numeric_df.empty:\n",
        "        buffer.write(\"### Estad√≠sticas descriptivas (basadas en todas las filas)\\n\")\n",
        "        buffer.write(numeric_df.describe().to_string())\n",
        "    else:\n",
        "        buffer.write(\"No hay columnas num√©ricas para mostrar estad√≠sticas.\\n\")\n",
        "    buffer.write(\"\\n\\n### Valores faltantes\\n\")\n",
        "    missing_values = df.isnull().sum()\n",
        "    missing_df = pd.DataFrame({\n",
        "        'Columna': missing_values.index,\n",
        "        'Valores faltantes': missing_values.values,\n",
        "        'Porcentaje': (missing_values.values / len(df)) * 100\n",
        "    })\n",
        "    buffer.write(missing_df.to_string(index=False))\n",
        "    buffer.write(\"\\n\\n### Tipos de datos\\n\")\n",
        "    dtypes_df = pd.DataFrame({\n",
        "        'Columna': df.dtypes.index,\n",
        "        'Tipo': df.dtypes.values\n",
        "    })\n",
        "    buffer.write(dtypes_df.to_string(index=False))\n",
        "    return buffer.getvalue()\n",
        "\n",
        "def generate_visualizations(df, target_col=None, cat_col=None):\n",
        "    plots_info = []\n",
        "\n",
        "    # Automatically select target and categorical columns if not provided\n",
        "    if target_col is None:\n",
        "        target_col = 'Riesgo_Cardiovascular'\n",
        "    if cat_col is None:\n",
        "        cat_cols = df.select_dtypes(include=['object', 'category']).columns\n",
        "        cat_col = cat_cols[0] if len(cat_cols) > 0 else None\n",
        "\n",
        "    if df.shape[0] < 10:\n",
        "        print(\"‚ö†Ô∏è Advertencia: El dataset tiene menos de 10 filas, lo que puede limitar la calidad de las visualizaciones.\")\n",
        "\n",
        "    # 1. Bar plot of target column distribution\n",
        "    if target_col and target_col in df.columns:\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.countplot(x=target_col, data=df, palette='Blues')\n",
        "        plt.title('Distribuci√≥n del Riesgo Cardiovascular', fontsize=14)\n",
        "        plt.xlabel('Riesgo Cardiovascular (0: Bajo, 1: Alto)', fontsize=12)\n",
        "        plt.ylabel('Frecuencia', fontsize=12)\n",
        "        plt.tight_layout()\n",
        "        filename = 'visualizations/dist_target.png'\n",
        "        plt.savefig(filename)\n",
        "        plt.close()\n",
        "        plots_info.append({\n",
        "            'title': 'Distribuci√≥n del Riesgo Cardiovascular',\n",
        "            'filename': filename,\n",
        "            'type': 'barplot'\n",
        "        })\n",
        "\n",
        "    # 2. Bar plot of top categories\n",
        "    if cat_col and cat_col in df.columns:\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        value_counts = df[cat_col].value_counts().head(10)\n",
        "        if len(value_counts) < 2:\n",
        "            print(f\"‚ö†Ô∏è Advertencia: La categor√≠a seleccionada tiene menos de 2 valores √∫nicos, lo que limita el an√°lisis.\")\n",
        "        sns.barplot(x=value_counts.index, y=value_counts.values, palette='Blues')\n",
        "        plt.title(f'Conteo de categor√≠as en {cat_col} (Top 10)', fontsize=14)\n",
        "        plt.xticks(rotation=45, ha='right', fontsize=10)\n",
        "        plt.ylabel('Cantidad', fontsize=12)\n",
        "        plt.tight_layout()\n",
        "        filename = 'visualizations/count_category.png'\n",
        "        plt.savefig(filename)\n",
        "        plt.close()\n",
        "        plots_info.append({\n",
        "            'title': f'Conteo de categor√≠as en {cat_col} (Top 10)',\n",
        "            'filename': filename,\n",
        "            'type': 'barplot'\n",
        "        })\n",
        "\n",
        "    # 3. Correlation heatmap\n",
        "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "    if len(numeric_cols) > 1:\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        corr_matrix = df[numeric_cols].corr()\n",
        "        mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
        "        sns.heatmap(corr_matrix, mask=mask, annot=True, cmap='Blues', fmt='.2f')\n",
        "        plt.title('Matriz de Correlaci√≥n', fontsize=14)\n",
        "        plt.tight_layout()\n",
        "        filename = 'visualizations/correlation_matrix.png'\n",
        "        plt.savefig(filename)\n",
        "        plt.close()\n",
        "        plots_info.append({\n",
        "            'title': 'Matriz de Correlaci√≥n',\n",
        "            'filename': filename,\n",
        "            'type': 'heatmap'\n",
        "        })\n",
        "\n",
        "    return plots_info\n",
        "\n",
        "\"\"\"## Predicci√≥n de Riesgo Cardiovascular\"\"\"\n",
        "def preprocess_data(df, target_col=None, categorical_cols=None, numerical_cols=None):\n",
        "    if df.shape[0] < 10:\n",
        "        raise ValueError(\"El dataset tiene menos de 10 filas, lo que es insuficiente para entrenar un modelo.\")\n",
        "\n",
        "    # Espec√≠fico para el dataset conductores_salud\n",
        "    target_col = 'Riesgo_Cardiovascular'\n",
        "    categorical_cols = ['Genero', 'Fuma']\n",
        "    numerical_cols = ['Edad', 'IMC', 'Colesterol', 'Trigliceridos', 'Frecuencia_Cardiaca',\n",
        "                      'Presion_Sistolica', 'Presion_Diastolica', 'Nivel_Estres', 'Actividad_Fisica']\n",
        "\n",
        "    # Verificar que las columnas requeridas est√©n presentes\n",
        "    required_cols = [target_col] + categorical_cols + numerical_cols\n",
        "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
        "    if missing_cols:\n",
        "        raise ValueError(f\"Faltan las siguientes columnas en el archivo: {', '.join(missing_cols)}\")\n",
        "\n",
        "    # Handle missing values\n",
        "    df = df.dropna(subset=[target_col])\n",
        "    for col in numerical_cols:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
        "        df[col] = df[col].fillna(df[col].median())\n",
        "    for col in categorical_cols:\n",
        "        df[col] = df[col].fillna(df[col].mode()[0])\n",
        "\n",
        "    # Encode categorical variables\n",
        "    le = LabelEncoder()\n",
        "    for col in categorical_cols:\n",
        "        df[col] = le.fit_transform(df[col])\n",
        "\n",
        "    # Normalize numerical features\n",
        "    scaler = StandardScaler()\n",
        "    df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
        "\n",
        "    return df, scaler, target_col\n",
        "\n",
        "def train_model(df_encoded, target_col):\n",
        "    X = df_encoded.drop(columns=[target_col], axis=1)\n",
        "    y = df_encoded[target_col]\n",
        "\n",
        "    # Verify numeric data\n",
        "    non_numeric_cols = X.select_dtypes(exclude=[np.number]).columns\n",
        "    if len(non_numeric_cols) > 0:\n",
        "        raise ValueError(f\"El conjunto de caracter√≠sticas contiene columnas no num√©ricas: {non_numeric_cols.tolist()}\")\n",
        "\n",
        "    # Split the data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Build the Keras model for binary classification\n",
        "    model = Sequential([\n",
        "        Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dense(16, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    # Compile and train\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2, verbose=0)\n",
        "\n",
        "    # Evaluate\n",
        "    y_pred_prob = model.predict(X_test)\n",
        "    y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
        "\n",
        "    # Metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "    # Generate visualizations\n",
        "    plots_info = []\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "    plt.title('Matriz de Confusi√≥n')\n",
        "    plt.xlabel('Predicho')\n",
        "    plt.ylabel('Real')\n",
        "    plt.tight_layout()\n",
        "    filename = 'visualizations/confusion_matrix.png'\n",
        "    plt.savefig(filename)\n",
        "    plt.close()\n",
        "    plots_info.append({\n",
        "        'title': 'Matriz de Confusi√≥n',\n",
        "        'filename': filename,\n",
        "        'type': 'heatmap'\n",
        "    })\n",
        "\n",
        "    # Feature Importance (Correlation-based)\n",
        "    correlations = df_encoded.corr()[target_col].abs().sort_values(ascending=False)\n",
        "    top_features = correlations[1:6]\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.barplot(x=top_features.values, y=top_features.index, palette='Blues')\n",
        "    plt.title('Importancia de Caracter√≠sticas (Correlaci√≥n)', fontsize=14)\n",
        "    plt.xlabel('Correlaci√≥n Absoluta', fontsize=12)\n",
        "    plt.tight_layout()\n",
        "    filename = 'visualizations/feature_importance.png'\n",
        "    plt.savefig(filename)\n",
        "    plt.close()\n",
        "    plots_info.append({\n",
        "        'title': 'Importancia de Caracter√≠sticas',\n",
        "        'filename': filename,\n",
        "        'type': 'barplot'\n",
        "    })\n",
        "\n",
        "    return accuracy, precision, recall, f1, plots_info, model, X_test, y_test, y_pred, correlations\n",
        "\n",
        "\"\"\"## Integraci√≥n con Gemini API\"\"\"\n",
        "def query_gemini_analysis(df, query, model, target_col='Riesgo_Cardiovascular', cat_col=None, year_col=None, region_cols=None):\n",
        "    try:\n",
        "        if df.shape[0] < 10:\n",
        "            return \"‚ö†Ô∏è Los datos son insuficientes (menos de 10 filas). Por favor, proporciona un dataset m√°s grande para un an√°lisis confiable.\"\n",
        "\n",
        "        # Automatically select columns\n",
        "        if cat_col is None:\n",
        "            cat_col = 'Genero'\n",
        "        if year_col is None:\n",
        "            year_col = None\n",
        "        if region_cols is None:\n",
        "            region_cols = []\n",
        "\n",
        "        # Prepare data summary for Gemini\n",
        "        df_info = df.head(100).to_string()  # Mostrar las primeras 100 filas como muestra\n",
        "        columns_info = \"\\n\".join([f\"- {col}: {df[col].dtype}\" for col in df.columns])\n",
        "        numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "        stats = \"\\n\".join([f\"- {col}: min={df[col].min()}, max={df[col].max()}, mean={df[col].mean()}\" for col in numeric_cols])\n",
        "\n",
        "        # Common instructions for all prompts\n",
        "        base_instructions = \"\"\"\n",
        "        Instrucciones:\n",
        "        - Responde SOLO a la consulta proporcionada, utilizando √∫nicamente los datos y el an√°lisis proporcionados.\n",
        "        - NO hagas suposiciones ni generes datos hipot√©ticos.\n",
        "        - Proporciona una respuesta concisa, clara y accionable.\n",
        "        - Si los datos son insuficientes, indica claramente que los datos son limitados y sugiere c√≥mo obtener un an√°lisis m√°s robusto.\n",
        "        - Evita a√±adir informaci√≥n o recomendaciones no solicitadas.\n",
        "        \"\"\"\n",
        "\n",
        "        # Specific analysis for predefined questions\n",
        "        if \"highest\" in query.lower() and \"potential\" in query.lower() and cat_col:\n",
        "            df_encoded, _, _ = preprocess_data(df, target_col, ['Genero', 'Fuma'])\n",
        "            accuracy, precision, recall, f1, _, model, X_test, y_test, y_pred, _ = train_model(df_encoded, target_col)\n",
        "            category_risk = df.groupby(cat_col)[target_col].mean().sort_values(ascending=False)\n",
        "            top_category = category_risk.index[0]\n",
        "            prompt = f\"\"\"\n",
        "            {base_instructions}\n",
        "\n",
        "            Datos:\n",
        "            COLUMNAS:\n",
        "            {columns_info}\n",
        "\n",
        "            ESTAD√çSTICAS:\n",
        "            {stats}\n",
        "\n",
        "            MUESTRA:\n",
        "            {df_info}\n",
        "\n",
        "            An√°lisis: La categor√≠a con mayor riesgo promedio es '{top_category}' con {category_risk.iloc[0]:.2f} (Accuracy del modelo: {accuracy:.2f}). Nota: Los datos tienen {df.shape[0]} filas.\n",
        "            Confirma este resultado y explica brevemente, en no m√°s de 100 palabras, por qu√© esta categor√≠a tiene alto riesgo cardiovascular, bas√°ndote en el modelo y los datos. Sugiere c√≥mo mejorar el an√°lisis con m√°s datos.\n",
        "            \"\"\"\n",
        "        elif \"combination\" in query.lower() and \"potential\" in query.lower():\n",
        "            cat_cols = ['Genero', 'Fuma']\n",
        "            df_encoded, _, _ = preprocess_data(df, target_col, cat_cols)\n",
        "            accuracy, precision, recall, f1, _, model, X_test, y_test, y_pred, _ = train_model(df_encoded, target_col)\n",
        "            combo_risk = df.groupby(cat_cols)[target_col].mean().sort_values(ascending=False)\n",
        "            if not combo_risk.empty:\n",
        "                top_combo = combo_risk.index[0]\n",
        "                top_risk = combo_risk.iloc[0]\n",
        "                prompt = f\"\"\"\n",
        "                {base_instructions}\n",
        "\n",
        "                Datos:\n",
        "                COLUMNAS:\n",
        "                {columns_info}\n",
        "\n",
        "                ESTAD√çSTICAS:\n",
        "                {stats}\n",
        "\n",
        "                MUESTRA:\n",
        "                {df_info}\n",
        "\n",
        "                An√°lisis: La combinaci√≥n con mayor riesgo es '{top_combo[0]}'/'{top_combo[1]}' con {top_risk:.2f} (Accuracy del modelo: {accuracy:.2f}). Nota: Los datos tienen {df.shape[0]} filas.\n",
        "                Confirma este resultado y explica brevemente, en no m√°s de 100 palabras, por qu√© esta combinaci√≥n tiene alto riesgo, bas√°ndote en el modelo. Sugiere c√≥mo mejorar el an√°lisis con m√°s datos.\n",
        "                \"\"\"\n",
        "            else:\n",
        "                return \"‚ö†Ô∏è Los datos no contienen informaci√≥n suficiente para determinar combinaciones de categor√≠as.\"\n",
        "        elif \"marketing strategies\" in query.lower() and cat_col:\n",
        "            df_encoded, _, _ = preprocess_data(df, target_col, ['Genero', 'Fuma'])\n",
        "            accuracy, precision, recall, f1, _, model, X_test, y_test, y_pred, _ = train_model(df_encoded, target_col)\n",
        "            top_cats = df.groupby(cat_col)[target_col].mean().sort_values(ascending=False).head(2).index.tolist()\n",
        "            prompt = f\"\"\"\n",
        "            {base_instructions}\n",
        "\n",
        "            Datos:\n",
        "            COLUMNAS:\n",
        "            {columns_info}\n",
        "\n",
        "            ESTAD√çSTICAS:\n",
        "            {stats}\n",
        "\n",
        "            MUESTRA:\n",
        "            {df_info}\n",
        "\n",
        "            An√°lisis: Las categor√≠as con mayor riesgo son {', '.join(top_cats)}. Modelo Accuracy: {accuracy:.2f}. Nota: Los datos tienen {df.shape[0]} filas.\n",
        "            Genera 3 estrategias de prevenci√≥n espec√≠ficas y breves (m√°ximo 50 palabras cada una) para reducir el riesgo cardiovascular en estas categor√≠as, bas√°ndote en el modelo y los datos. Sugiere c√≥mo mejorar las estrategias con m√°s datos.\n",
        "            \"\"\"\n",
        "        else:\n",
        "            prompt = f\"\"\"\n",
        "            {base_instructions}\n",
        "\n",
        "            Datos:\n",
        "            COLUMNAS:\n",
        "            {columns_info}\n",
        "\n",
        "            ESTAD√çSTICAS:\n",
        "            {stats}\n",
        "\n",
        "            MUESTRA:\n",
        "            {df_info}\n",
        "\n",
        "            Consulta: {query}\n",
        "            Responde √∫nicamente a la consulta, utilizando los datos proporcionados. Proporciona un an√°lisis claro, conciso y accionable en no m√°s de 150 palabras. Si los datos son insuficientes, ind√≠calos claramente y sugiere c√≥mo obtener un an√°lisis m√°s robusto.\n",
        "            \"\"\"\n",
        "\n",
        "        # Query Gemini API\n",
        "        response = model.generate_content(prompt)\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        return f\"Error al consultar a Gemini: {str(e)}\"\n",
        "\n",
        "\"\"\"## Interfaz de usuario con Gradio\"\"\"\n",
        "def create_gradio_interface():\n",
        "    df = None\n",
        "    model = None\n",
        "    gemini_model = None\n",
        "    X_test = None\n",
        "    y_test = None\n",
        "    y_pred = None\n",
        "    target_col = 'Riesgo_Cardiovascular'\n",
        "    categorical_cols = ['Genero', 'Fuma']\n",
        "    numerical_cols = ['Edad', 'IMC', 'Colesterol', 'Trigliceridos', 'Frecuencia_Cardiaca',\n",
        "                      'Presion_Sistolica', 'Presion_Diastolica', 'Nivel_Estres', 'Actividad_Fisica']\n",
        "\n",
        "    def upload_file(file):\n",
        "        try:\n",
        "            nonlocal df, target_col, categorical_cols, numerical_cols\n",
        "            file_extension = os.path.splitext(file.name)[1].lower()\n",
        "            if file_extension == '.csv':\n",
        "                df = pd.read_csv(file.name)\n",
        "            elif file_extension == '.xlsx':\n",
        "                df = pd.read_excel(file.name, engine='openpyxl')\n",
        "            else:\n",
        "                return None, \"Formato no soportado. Usa .csv o .xlsx.\", \"Error\", [], [], []\n",
        "\n",
        "            # Corregir codificaci√≥n de 'S√É¬≠' a 'S√≠'\n",
        "            if 'Fuma' in df.columns:\n",
        "                df['Fuma'] = df['Fuma'].replace('S√É¬≠', 'S√≠')\n",
        "\n",
        "            stats = generate_csv_stats(df, max_preview_rows=100)\n",
        "            return (df.head(100).to_html(), stats, f\"Archivo {file_extension} cargado correctamente. Total de filas: {df.shape[0]}\",\n",
        "                    [target_col], categorical_cols, numerical_cols)\n",
        "        except Exception as e:\n",
        "            return None, f\"Error al cargar el archivo: {str(e)}\", \"Error\", [], [], []\n",
        "\n",
        "    def update_columns(selected_target, selected_categorical, selected_numerical):\n",
        "        nonlocal target_col, categorical_cols, numerical_cols\n",
        "        target_col = selected_target\n",
        "        categorical_cols = selected_categorical\n",
        "        numerical_cols = selected_numerical\n",
        "        return f\"Configuraci√≥n actualizada: Objetivo seleccionado, {len(categorical_cols)} categor√≠as, {len(numerical_cols)} variables num√©ricas\"\n",
        "\n",
        "    def set_api_key(api_key):\n",
        "        nonlocal gemini_model\n",
        "        success, model_instance = setup_gemini_api(api_key)\n",
        "        if success:\n",
        "            gemini_model = model_instance\n",
        "            return \"API de Gemini configurada correctamente\", api_key\n",
        "        else:\n",
        "            return \"Error al configurar la API de Gemini\", \"\"\n",
        "\n",
        "    def ask_gemini(query, api_key):\n",
        "        nonlocal df, gemini_model, target_col, categorical_cols\n",
        "        if df is None:\n",
        "            return \"Primero debes cargar un archivo CSV o XLSX\"\n",
        "        if not api_key or gemini_model is None:\n",
        "            return \"Primero debes configurar la API de Gemini\"\n",
        "        try:\n",
        "            cat_col = categorical_cols[0] if categorical_cols else None\n",
        "            return query_gemini_analysis(df, query, gemini_model, target_col, cat_col)\n",
        "        except Exception as e:\n",
        "            return f\"Error al consultar a Gemini: {str(e)}\"\n",
        "\n",
        "    def generate_plots():\n",
        "        nonlocal df, target_col, categorical_cols\n",
        "        if df is None:\n",
        "            return \"Primero debes cargar un archivo CSV o XLSX\", []\n",
        "        try:\n",
        "            cat_col = categorical_cols[0] if categorical_cols else None\n",
        "            plots_info = generate_visualizations(df, target_col, cat_col)\n",
        "            return \"Visualizaciones generadas correctamente\", [plot['filename'] for plot in plots_info]\n",
        "        except Exception as e:\n",
        "            return f\"Error al generar visualizaciones: {str(e)}\", []\n",
        "\n",
        "    def train_and_evaluate():\n",
        "        nonlocal df, model, X_test, y_test, y_pred, target_col, categorical_cols, numerical_cols\n",
        "        if df is None:\n",
        "            return \"Primero debes cargar un archivo CSV o XLSX\", [], \"\"\n",
        "        try:\n",
        "            df_encoded, _, target_col = preprocess_data(df, target_col, categorical_cols, numerical_cols)\n",
        "            accuracy, precision, recall, f1, plots_info, model, X_test, y_test, y_pred, _ = train_model(df_encoded, target_col)\n",
        "            metrics = f\"Accuracy: {accuracy:.4f}\\nPrecision: {precision:.4f}\\nRecall: {recall:.4f}\\nF1-Score: {f1:.4f}\"\n",
        "            return metrics, [plot['filename'] for plot in plots_info], \"Modelo entrenado correctamente\"\n",
        "        except Exception as e:\n",
        "            return f\"Error al entrenar el modelo: {str(e)}\", [], \"Error\"\n",
        "\n",
        "    with gr.Blocks(title=\"Predicci√≥n del Riesgo Cardiovascular\") as app:\n",
        "        gr.Markdown(\"# üìä Predicci√≥n del Riesgo Cardiovascular\")\n",
        "        gr.Markdown(\"Carga un archivo CSV o XLSX con datos de salud (puede tener m√∫ltiples filas, ej. 1000), analiza los datos, predice el riesgo cardiovascular y consulta patrones con Gemini AI.\")\n",
        "        saved_api_key = gr.State(\"\")\n",
        "        with gr.Tab(\"Cargar Datos\"):\n",
        "            with gr.Row():\n",
        "                with gr.Column(scale=1):\n",
        "                    file_input = gr.File(label=\"Selecciona un archivo CSV o XLSX\", file_types=[\".csv\", \".xlsx\"])\n",
        "                    upload_button = gr.Button(\"Cargar Archivo\")\n",
        "                    upload_status = gr.Textbox(label=\"Estado\", interactive=False)\n",
        "                with gr.Column(scale=2):\n",
        "                    data_preview = gr.HTML(label=\"Vista previa (Primeras 100 filas)\")\n",
        "                    data_stats = gr.Textbox(label=\"Estad√≠sticas (Basadas en todas las filas)\", interactive=False, max_lines=30)\n",
        "        with gr.Tab(\"Configurar An√°lisis\"):\n",
        "            target_dropdown = gr.Dropdown(label=\"Variable Objetivo\", choices=['Riesgo_Cardiovascular'], value='Riesgo_Cardiovascular', interactive=True)\n",
        "            categorical_checklist = gr.CheckboxGroup(label=\"Variables Categ√≥ricas\", choices=['Genero', 'Fuma'], value=['Genero', 'Fuma'], interactive=True)\n",
        "            numerical_checklist = gr.CheckboxGroup(label=\"Variables Num√©ricas\", choices=['Edad', 'IMC', 'Colesterol', 'Trigliceridos', 'Frecuencia_Cardiaca',\n",
        "                                                                                       'Presion_Sistolica', 'Presion_Diastolica', 'Nivel_Estres', 'Actividad_Fisica'],\n",
        "                                                  value=['Edad', 'IMC', 'Colesterol', 'Trigliceridos', 'Frecuencia_Cardiaca',\n",
        "                                                         'Presion_Sistolica', 'Presion_Diastolica', 'Nivel_Estres', 'Actividad_Fisica'], interactive=True)\n",
        "            update_button = gr.Button(\"Actualizar Configuraci√≥n\")\n",
        "            column_status = gr.Textbox(label=\"Estado de Configuraci√≥n\", interactive=False)\n",
        "        with gr.Tab(\"Configurar API\"):\n",
        "            gemini_api_key = gr.Textbox(label=\"API Key de Gemini AI\", type=\"password\")\n",
        "            api_button = gr.Button(\"Configurar API\")\n",
        "            api_status = gr.Textbox(label=\"Estado\", interactive=False)\n",
        "        with gr.Tab(\"Consultar Datos\"):\n",
        "            query_input = gr.Textbox(label=\"Consulta sobre los datos\", placeholder=\"Ej: ¬øQu√© categor√≠a tiene mayor riesgo cardiovascular?\")\n",
        "            query_button = gr.Button(\"Consultar a Gemini AI\")\n",
        "            query_result = gr.Markdown(label=\"Respuesta\")\n",
        "        with gr.Tab(\"Visualizaciones\"):\n",
        "            viz_button = gr.Button(\"Generar Visualizaciones\")\n",
        "            viz_status = gr.Textbox(label=\"Estado\", interactive=False)\n",
        "            viz_gallery = gr.Gallery(label=\"Gr√°ficos\", show_label=True, columns=2, rows=3, height=600)\n",
        "        with gr.Tab(\"Predicci√≥n\"):\n",
        "            pred_button = gr.Button(\"Entrenar y Evaluar Modelo\")\n",
        "            pred_metrics = gr.Textbox(label=\"M√©tricas del Modelo\", interactive=False)\n",
        "            pred_gallery = gr.Gallery(label=\"Gr√°ficos de Predicci√≥n\", show_label=True, columns=2, rows=2, height=600)\n",
        "            pred_status = gr.Textbox(label=\"Estado\", interactive=False)\n",
        "\n",
        "        upload_button.click(\n",
        "            upload_file,\n",
        "            inputs=[file_input],\n",
        "            outputs=[data_preview, data_stats, upload_status, target_dropdown, categorical_checklist, numerical_checklist]\n",
        "        )\n",
        "        update_button.click(\n",
        "            update_columns,\n",
        "            inputs=[target_dropdown, categorical_checklist, numerical_checklist],\n",
        "            outputs=[column_status]\n",
        "        )\n",
        "        api_button.click(set_api_key, inputs=[gemini_api_key], outputs=[api_status, saved_api_key])\n",
        "        query_button.click(ask_gemini, inputs=[query_input, saved_api_key], outputs=[query_result])\n",
        "        viz_button.click(generate_plots, inputs=[], outputs=[viz_status, viz_gallery])\n",
        "        pred_button.click(train_and_evaluate, inputs=[], outputs=[pred_metrics, pred_gallery, pred_status])\n",
        "\n",
        "    return app\n",
        "\n",
        "\"\"\"## Iniciar la aplicaci√≥n\"\"\"\n",
        "print(\"¬°Bienvenido al Sistema de Predicci√≥n del Riesgo Cardiovascular!\")\n",
        "print(\"Este notebook te permite:\")\n",
        "print(\"1. Cargar un archivo CSV o XLSX con datos de conductores (puede tener m√∫ltiples filas, ej. 1000)\")\n",
        "print(\"2. Configurar el an√°lisis seleccionando variables objetivo, categ√≥ricas y num√©ricas\")\n",
        "print(\"3. Analizar datos (estad√≠sticas y visualizaciones basadas en todas las filas)\")\n",
        "print(\"4. Predecir el riesgo cardiovascular usando un modelo de red neuronal\")\n",
        "print(\"5. Consultar patrones y recomendaciones con Gemini AI\")\n",
        "print(\"\\nEjecuta la siguiente celda para iniciar la interfaz.\")\n",
        "app = create_gradio_interface()\n",
        "app.launch(debug=True)\n",
        "\n",
        "\"\"\"\n",
        "## Instrucciones de uso\n",
        "\n",
        "1. **Instalar dependencias**:\n",
        "   - Ejecuta en Colab:\n",
        "     ```bash\n",
        "     !pip install numpy pandas matplotlib seaborn tensorflow google-generativeai gradio scikit-learn openpyxl\"\"\""
      ]
    }
  ]
}